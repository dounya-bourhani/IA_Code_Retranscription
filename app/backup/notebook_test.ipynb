{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf870481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en train et test avec un ratio de 70/30\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "Ici, on utilise la fonction train_test_split de la bibliothèque sklearn.model_selection pour séparer les données en deux ensembles: un ensemble d'entraînement (X_train, y_train) et un ensemble de test (X_test, y_test). Le paramètre test_size permet de spécifier la taille de l'ensemble de test (ici, 30% des données), et le paramètre random_state permet de fixer la graine aléatoire pour des résultats reproductibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1dfaa7",
   "metadata": {},
   "source": [
    "Dans ce notebook, les données de l'ensemble Iris sont chargées à l'aide de la fonction load\\_iris() de la bibliothèque sklearn.datasets. Ensuite, ces données sont divisées en deux ensembles: un ensemble d'entraînement et un ensemble de test, en utilisant la fonction train\\_test\\_split() de la bibliothèque sklearn.model\\_selection. Le ratio de division est de 70% pour l'ensemble d'entraînement et 30% pour l'ensemble de test. Le paramètre random\\_state est défini sur 42 pour obtenir des résultats reproductibles. Les données d'entraînement sont représentées par X\\_train et y\\_train, tandis que les données de test sont représentées par X\\_test et y\\_test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d84e4",
   "metadata": {},
   "source": [
    "# Importance of Train-Test Split\n",
    "\n",
    "The train-test split is a fundamental technique in machine learning that helps to evaluate the performance of a model and prevent overfitting. By dividing the dataset into two separate sets, one for training and one for testing, we can assess how well our model generalizes to new, unseen data. This split ensures that the model is not simply memorizing the training data, but is instead learning patterns and relationships that can be applied to future observations. By using a separate test set, we can have confidence that our model's performance is not artificially inflated and is instead robust and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd927c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) # centering and reduction on the training data\n",
    "X_test = scaler.transform(X_test) # only reduction on the test data, using the same parameters as calculated with the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18961121",
   "metadata": {},
   "source": [
    "Cette courte section de code utilise la bibliothèque matplotlib de Python pour créer un graphique de dispersion des données d'entraînement X\\_train du jeu de données iris. Il importe matplotlib sous le nom plt et trace un scatter plot en utilisant les deux premières colonnes de X\\_train pour les axes x et y. Le dernier point de X\\_train est mis en évidence en rouge. Le graphique est affiché avec la méthode show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ba893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_pos)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "sns.plotroc(fpr, tpr)\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3eb4b",
   "metadata": {},
   "source": [
    "Dans ce notebook, les données de l'ensemble Iris sont chargées à l'aide de la fonction load\\_iris() de la bibliothèque sklearn.datasets. Ensuite, les données sont divisées en un ensemble d'entraînement et un ensemble de test à l'aide de la fonction train\\_test\\_split() de la bibliothèque sklearn.model\\_selection, avec un ratio de 70/30. Les données sont ensuite normalisées à l'aide de la fonction StandardScaler() de la bibliothèque sklearn.preprocessing. Un classifieur logistique est entraîné sur les données d'entraînement à l'aide de la fonction LogisticRegression() de la bibliothèque sklearn.linear\\_model. Les probabilités prédites pour l'ensemble de test sont ensuite calculées à l'aide de la méthode predict\\_proba() du classifieur logistique. La courbe ROC (Receiver Operating Characteristic) est tracée en utilisant les fonctions roc\\_curve() et auc() de la bibliothèque sklearn.metrics, et la bibliothèque seaborn est utilisée pour afficher la courbe ROC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
